{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import sys"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt\n", "from sklearn.ensemble import ExtraTreesClassifier \n", "from sklearn.model_selection import train_test_split\n", "from sklearn.metrics import classification_report"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from utilities import visualize_classifier"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load input data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["input_file = 'data_imbalance.txt'\n", "data = np.loadtxt(input_file, delimiter=',')\n", "X, y = data[:, :-1], data[:, -1]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Separate input data into two classes based on labels"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class_0 = np.array(X[y==0])\n", "class_1 = np.array(X[y==1])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Visualize input data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()\n", "plt.scatter(class_0[:, 0], class_0[:, 1], s=75, facecolors='black', \n", "                edgecolors='black', linewidth=1, marker='x')\n", "plt.scatter(class_1[:, 0], class_1[:, 1], s=75, facecolors='white', \n", "                edgecolors='black', linewidth=1, marker='o')\n", "plt.title('Input data')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Split data into training and testing datasets "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train, X_test, y_train, y_test = train_test_split(\n", "        X, y, test_size=0.25, random_state=5)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Extremely Random Forests classifier"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["params = {'n_estimators': 100, 'max_depth': 4, 'random_state': 0}\n", "if len(sys.argv) > 1:\n", "    if sys.argv[1] == 'balance':\n", "        params = {'n_estimators': 100, 'max_depth': 4, 'random_state': 0, 'class_weight': 'balanced'}\n", "    else:\n", "        raise TypeError(\"Invalid input argument; should be 'balance'\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["classifier = ExtraTreesClassifier(**params)\n", "classifier.fit(X_train, y_train)\n", "visualize_classifier(classifier, X_train, y_train, 'Training dataset')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_test_pred = classifier.predict(X_test)\n", "visualize_classifier(classifier, X_test, y_test, 'Test dataset')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Evaluate classifier performance"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class_names = ['Class-0', 'Class-1']\n", "print(\"\\n\" + \"#\"*40)\n", "print(\"\\nClassifier performance on training dataset\\n\")\n", "print(classification_report(y_train, classifier.predict(X_train), target_names=class_names))\n", "print(\"#\"*40 + \"\\n\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"#\"*40)\n", "print(\"\\nClassifier performance on test dataset\\n\")\n", "print(classification_report(y_test, y_test_pred, target_names=class_names))\n", "print(\"#\"*40 + \"\\n\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["########################################################################################"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt\n", "from sklearn.metrics import classification_report\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.tree import DecisionTreeClassifier"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from utilities import visualize_classifier"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load input data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["input_file = 'data_decision_trees.txt'\n", "data = np.loadtxt(input_file, delimiter=',')\n", "X, y = data[:, :-1], data[:, -1]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Separate input data into two classes based on labels"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class_0 = np.array(X[y==0])\n", "class_1 = np.array(X[y==1])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Visualize input data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()\n", "plt.scatter(class_0[:, 0], class_0[:, 1], s=75, facecolors='black', \n", "        edgecolors='black', linewidth=1, marker='x')\n", "plt.scatter(class_1[:, 0], class_1[:, 1], s=75, facecolors='white', \n", "        edgecolors='black', linewidth=1, marker='o')\n", "plt.title('Input data')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Split data into training and testing datasets "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=5)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Decision Trees classifier "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["params = {'random_state': 0, 'max_depth': 4}\n", "classifier = DecisionTreeClassifier(**params)\n", "classifier.fit(X_train, y_train)\n", "visualize_classifier(classifier, X_train, y_train, 'Training dataset')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_test_pred = classifier.predict(X_test)\n", "visualize_classifier(classifier, X_test, y_test, 'Test dataset')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Evaluate classifier performance"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class_names = ['Class-0', 'Class-1']\n", "print(\"\\n\" + \"#\"*40)\n", "print(\"\\nClassifier performance on training dataset\\n\")\n", "print(classification_report(y_train, classifier.predict(X_train), target_names=class_names))\n", "print(\"#\"*40 + \"\\n\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"#\"*40)\n", "print(\"\\nClassifier performance on test dataset\\n\")\n", "print(classification_report(y_test, y_test_pred, target_names=class_names))\n", "print(\"#\"*40 + \"\\n\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["########################################################################################"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt\n", "from sklearn.tree import DecisionTreeRegressor\n", "from sklearn.ensemble import AdaBoostRegressor\n", "from sklearn import datasets\n", "from sklearn.metrics import mean_squared_error, explained_variance_score\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.utils import shuffle"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load housing data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["housing_data = datasets.load_boston() "]}, {"cell_type": "markdown", "metadata": {}, "source": ["Shuffle the data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X, y = shuffle(housing_data.data, housing_data.target, random_state=7)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Split data into training and testing datasets "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["AdaBoost Regressor model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["regressor = AdaBoostRegressor(DecisionTreeRegressor(max_depth=4), \n", "        n_estimators=400, random_state=7)\n", "regressor.fit(X_train, y_train)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Evaluate performance of AdaBoost regressor"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_pred = regressor.predict(X_test)\n", "mse = mean_squared_error(y_test, y_pred)\n", "evs = explained_variance_score(y_test, y_pred )\n", "print(\"\\nADABOOST REGRESSOR\")\n", "print(\"Mean squared error =\", round(mse, 2))\n", "print(\"Explained variance score =\", round(evs, 2))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Extract feature importances"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["feature_importances = regressor.feature_importances_\n", "feature_names = housing_data.feature_names"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Normalize the importance values "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["feature_importances = 100.0 * (feature_importances / max(feature_importances))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Sort the values and flip them"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["index_sorted = np.flipud(np.argsort(feature_importances))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Arrange the X ticks"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pos = np.arange(index_sorted.shape[0]) + 0.5"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot the bar graph"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()\n", "plt.bar(pos, feature_importances[index_sorted], align='center')\n", "plt.xticks(pos, feature_names[index_sorted])\n", "plt.ylabel('Relative Importance')\n", "plt.title('Feature importance using AdaBoost regressor')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["########################################################################################"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt\n", "from sklearn.metrics import classification_report\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.model_selection import GridSearchCV"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.ensemble import ExtraTreesClassifier\n", "from sklearn.metrics import classification_report"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Define the minimum and maximum values for X and Y<br>\n", "that will be used in the mesh grid"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def visualize_classifier(classifier, X, y):\n", "  min_x, max_x = X[:, 0].min() - 1.0, X[:, 0].max() + 1.0\n", "  min_y, max_y = X[:, 1].min() - 1.0, X[:, 1].max() + 1.0"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"\\nLoad file\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load input data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["input_file = 'data_random_forests.txt'\n", "data = np.loadtxt(input_file, delimiter=',')\n", "X, y = data[:, :-1], data[:, -1]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Separate input data into three classes based on labels"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class_0 = np.array(X[y==0])\n", "class_1 = np.array(X[y==1])\n", "class_2 = np.array(X[y==2])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Split the data into training and testing datasets "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train, X_test, y_train, y_test = train_test_split(\n", "        X, y, test_size=0.25, random_state=5)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Define the parameter grid "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["parameter_grid = [ {'n_estimators': [100], 'max_depth': [2, 4, 7, 12, 16]},\n", "                   {'max_depth': [4], 'n_estimators': [25, 50, 100, 250]}\n", "                 ]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["metrics = ['precision_weighted', 'recall_weighted']"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for metric in metrics:\n", "    print(\"\\n##### Searching optimal parameters for\", metric)\n", "    classifier = GridSearchCV(\n", "            ExtraTreesClassifier(random_state=0), \n", "            parameter_grid, cv=5, scoring=metric)\n", "    classifier.fit(X_train, y_train)\n", "    \n", "    print(\"\\nGrid scores for the parameter grid:\")\n", "    for results in classifier.cv_results_:\n", "        print(results)\n", "    print(\"\\nBest parameters:\", classifier.best_params_)\n", "    y_pred = classifier.predict(X_test)\n", "    print(\"\\nPerformance report:\\n\")\n", "    print(classification_report(y_test, y_pred))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["########################################################################################"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import argparse\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from sklearn.metrics import classification_report\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n", "from sklearn.metrics import classification_report\n", "from utilities import visualize_classifier"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Argument parser"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def build_arg_parser():\n", " parser = argparse.ArgumentParser(description='Classify data using \\\n", " Ensemble Learning techniques')\n", " parser.add_argument('--classifier-type', dest='classifier_type',\n", " required=True, choices=['rf', 'erf'], help=\"Type of classifier \\\n", " to use; can be either 'rf' or 'erf'\")\n", " return parser\n", "if __name__=='__main__':\n", " # Parse the input arguments\n", " args = build_arg_parser().parse_args()\n", " classifier_type = args.classifier_type\n", "# Load input data\n", " input_file = 'data_random_forests.txt'\n", " data = np.loadtxt(input_file, delimiter=',')\n", " X, y = data[:, :-1], data[:, -1]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Separate input data into three classes based on labels"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": [" class_0 = np.array(X[y==0])\n", " class_1 = np.array(X[y==1])\n", " class_2 = np.array(X[y==2])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": [" # Visualize input data\n", " plt.figure()\n", " plt.scatter(class_0[:, 0], class_0[:, 1], s=75,\n", "             facecolors='white',\n", "             edgecolors='black', linewidth=1, marker='s')\n", " plt.scatter(class_1[:, 0], class_1[:, 1], s=75, facecolors='white',\n", " edgecolors='black', linewidth=1, marker='o')\n", " plt.scatter(class_2[:, 0], class_2[:, 1], s=75,\n", "facecolors='white',\n", " edgecolors='black', linewidth=1, marker='^')\n", " plt.title('Input data')\n", " # Split data into training and testing datasets\n", " X_train, X_test, y_train, y_test = train_test_split(\n", "     X, y, test_size=0.25, random_state=5)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": [" # Ensemble Learning classifier\n", " params = {'n_estimators': 100, 'max_depth': 4, 'random_state': 0}\n", "if classifier_type == 'rf':\n", "     classifier = RandomForestClassifier(**params)\n", "else:\n", "     classifier = ExtraTreesClassifier(**params)\n", "     classifier.fit(X_train, y_train)\n", "visualize_classifier(classifier, X_train, y_train, 'Training dataset')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_test_pred = classifier.predict(X_test)\n", "visualize_classifier(classifier, X_test, y_test, 'Test dataset')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Evaluate classifier performance"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class_names = ['Class-0', 'Class-1', 'Class-2']"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"\\n\" + \"#\" * 40)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"\\nClassifier performance on training dataset\\n\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(classification_report(y_train, classifier.predict(X_train), target_names=class_names))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"#\" * 40 + \"\\n\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"#\" * 40)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"\\nClassifier performance on test dataset\\n\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(classification_report(y_test, y_test_pred, target_names=class_names))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"#\" * 40 + \"\\n\")\n", "##########################################################################################"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt\n", "from sklearn.metrics import classification_report\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n", "from sklearn.metrics import classification_report"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from utilities import visualize_classifier"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__=='__main__':\n", "    # Parse the input arguments\n", "    classifier_type = 'erf'\n", "    #classifier_type = 'rf'\n", "    # Load input data\n", "    input_file = 'data_random_forests.txt'\n", "    data = np.loadtxt(input_file, delimiter=',')\n", "    X, y = data[:, :-1], data[:, -1]\n\n", "    # Separate input data into three classes based on labels\n", "    class_0 = np.array(X[y==0])\n", "    class_1 = np.array(X[y==1])\n", "    class_2 = np.array(X[y==2])\n\n", "    # Visualize input data\n", "    plt.figure()\n", "    plt.scatter(class_0[:, 0], class_0[:, 1], s=75, facecolors='white', \n", "                    edgecolors='black', linewidth=1, marker='s')\n", "    plt.scatter(class_1[:, 0], class_1[:, 1], s=75, facecolors='white', \n", "                    edgecolors='black', linewidth=1, marker='o')\n", "    plt.scatter(class_2[:, 0], class_2[:, 1], s=75, facecolors='white', \n", "                    edgecolors='black', linewidth=1, marker='^')\n", "    plt.title('Input data')\n\n", "    # Split data into training and testing datasets \n", "    X_train, X_test, y_train, y_test = train_test_split(\n", "            X, y, test_size=0.25, random_state=5)\n\n", "    # Ensemble Learning classifier\n", "    params = {'n_estimators': 100, 'max_depth': 4, 'random_state': 0}\n", "    if classifier_type == 'rf':\n", "        classifier = RandomForestClassifier(**params)\n", "    else:\n", "        classifier = ExtraTreesClassifier(**params)\n", "    classifier.fit(X_train, y_train)\n", "    visualize_classifier(classifier, X_train, y_train, 'Training dataset')\n", "    y_test_pred = classifier.predict(X_test)\n", "    visualize_classifier(classifier, X_test, y_test, 'Test dataset')\n\n", "    # Evaluate classifier performance\n", "    class_names = ['Class-0', 'Class-1', 'Class-2']\n", "    print(\"\\n\" + \"#\"*40)\n", "    print(\"\\nClassifier performance on training dataset\\n\")\n", "    print(classification_report(y_train, classifier.predict(X_train), target_names=class_names))\n", "    print(\"#\"*40 + \"\\n\")\n", "    print(\"#\"*40)\n", "    print(\"\\nClassifier performance on test dataset\\n\")\n", "    print(classification_report(y_test, y_test_pred, target_names=class_names))\n", "    print(\"#\"*40 + \"\\n\")\n\n", "    # Compute confidence\n", "    test_datapoints = np.array([[5, 5], [3, 6], [6, 4], [7, 2], [4, 4], [5, 2]])\n", "    print(\"\\nConfidence measure:\")\n", "    for datapoint in test_datapoints:\n", "        probabilities = classifier.predict_proba([datapoint])[0]\n", "        predicted_class = 'Class-' + str(np.argmax(probabilities))\n", "        print('\\nDatapoint:', datapoint)\n", "        print('Predicted class:', predicted_class) \n\n", "    # Visualize the datapoints\n", "    visualize_classifier(classifier, test_datapoints, [0]*len(test_datapoints), \n", "            'Test datapoints')\n", "    plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["########################################################################################"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt\n", "from sklearn.metrics import classification_report\n", "#from sklearn import grid_search\n", "from sklearn.ensemble import ExtraTreesClassifier\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.metrics import classification_report"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from utilities import visualize_classifier"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load input data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["input_file = 'data_random_forests.txt'\n", "data = np.loadtxt(input_file, delimiter=',')\n", "X, y = data[:, :-1], data[:, -1]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Separate input data into three classes based on labels"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class_0 = np.array(X[y==0])\n", "class_1 = np.array(X[y==1])\n", "class_2 = np.array(X[y==2])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Split the data into training and testing datasets"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train, X_test, y_train, y_test = train_test_split.train_test_split(\n", "        X, y, test_size=0.25, random_state=5)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Define the parameter grid"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["parameter_grid = [ {'n_estimators': [100], 'max_depth': [2, 4, 7, 12, 16]},\n", "                   {'max_depth': [4], 'n_estimators': [25, 50, 100, 250]}\n", "                 ]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["metrics = ['precision_weighted', 'recall_weighted']"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for metric in metrics:\n", "    print(\"\\n##### Searching optimal parameters for\", metric)\n", "    classifier = grid_search.GridSearchCV(\n", "            ExtraTreesClassifier(random_state=0),\n", "            parameter_grid, cv=5, scoring=metric)\n", "    classifier.fit(X_train, y_train)\n", "    print(\"\\nGrid scores for the parameter grid:\")\n", "    for params, avg_score, _ in classifier.grid_scores_:\n", "        print(params, '-->', round(avg_score, 3))\n", "    print(\"\\nBest parameters:\", classifier.best_params_)\n", "    y_pred = classifier.predict(X_test)\n", "    print(\"\\nPerformance report:\\n\")\n", "    print(classification_report(y_test, y_pred))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["########################################################################################"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt\n", "from sklearn.metrics import classification_report, mean_absolute_error\n", "from sklearn.model_selection import train_test_split\n", "from sklearn import preprocessing\n", "from sklearn.ensemble import ExtraTreesRegressor\n", "from sklearn.metrics import classification_report"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load input data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["input_file = 'traffic_data.txt'\n", "data = []\n", "with open(input_file, 'r') as f:\n", "    for line in f.readlines():\n", "        items = line[:-1].split(',')\n", "        data.append(items)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data = np.array(data)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Convert string data to numerical data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["label_encoder = [] \n", "X_encoded = np.empty(data.shape)\n", "for i, item in enumerate(data[0]):\n", "    if item.isdigit():\n", "        X_encoded[:, i] = data[:, i]\n", "    else:\n", "        label_encoder.append(preprocessing.LabelEncoder())\n", "        X_encoded[:, i] = label_encoder[-1].fit_transform(data[:, i])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X = X_encoded[:, :-1].astype(int)\n", "y = X_encoded[:, -1].astype(int)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Split data into training and testing datasets "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train, X_test, y_train, y_test = train_test_split(\n", "        X, y, test_size=0.25, random_state=5)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Extremely Random Forests regressor"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["params = {'n_estimators': 100, 'max_depth': 4, 'random_state': 0}\n", "regressor = ExtraTreesRegressor(**params)\n", "regressor.fit(X_train, y_train)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Compute the regressor performance on test data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_pred = regressor.predict(X_test)\n", "print(\"Mean absolute error:\", round(mean_absolute_error(y_test, y_pred), 2))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Testing encoding on single data instance"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["test_datapoint = ['Saturday', '10:20', 'Atlanta', 'no']\n", "test_datapoint_encoded = [-1] * len(test_datapoint)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Predict the output for the test datapoint"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Predicted traffic:\", int(regressor.predict([test_datapoint_encoded])[0]))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["########################################################################################"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}